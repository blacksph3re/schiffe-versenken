{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from garage import wrap_experiment\n",
    "from garage.envs import GymEnv, normalize\n",
    "from garage.experiment import Snapshotter\n",
    "from garage.experiment.deterministic import set_seed\n",
    "from garage.sampler import RaySampler, MultiprocessingSampler, Sampler, LocalSampler\n",
    "from garage.tf.algos import PPO\n",
    "from garage.tf.baselines import GaussianMLPBaseline\n",
    "from garage.tf.policies import GaussianMLPPolicy\n",
    "from garage.trainer import TFTrainer\n",
    "import garage\n",
    "\n",
    "from dowel import logger, tabular\n",
    "import akro\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmh_to_ms(val):\n",
    "    return val/3.6\n",
    "\n",
    "specs = {\n",
    "    \"aMax\": 2,\n",
    "    \"bMax\": 9,\n",
    "    \"bComf\": 2,\n",
    "    \"jComf\": 2,\n",
    "    \"jMax\": 20,\n",
    "    \"jMin\": 20,\n",
    "    \"tTarget\": 1,\n",
    "    \"gapMin\": 2,\n",
    "    \"vTarget\": kmh_to_ms(50),\n",
    "    \"vMax\": kmh_to_ms(150),\n",
    "    \"vMin\": 0,\n",
    "    \"timestep\": 1,\n",
    "    \"clipdist\": 500,\n",
    "    \"gamma_gap\": 1,\n",
    "    \"gamma_follow\": 1,\n",
    "    \"gamma_accel\": 1,\n",
    "    \"gamma_jerk\": 1,\n",
    "    \"gamma_crit\": 1\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(envs, policy):\n",
    "    debug_memories = [[] for _ in envs]\n",
    "    state = np.array([e.reset()[0] for e in envs])\n",
    "    total_reward = 0\n",
    "\n",
    "    for i in range(0, 100):\n",
    "        action, policy_info = policy.get_actions(state)\n",
    "\n",
    "        statewrappers = [e.step(a) for a, e in zip(action, envs)]\n",
    "        \n",
    "        terminals = np.array([(s.step_type == garage.StepType.TERMINAL or s.step_type == garage.StepType.TIMEOUT) for s in statewrappers])\n",
    "        rewards = np.array([s.reward for s in statewrappers])\n",
    "        total_reward += np.sum(rewards)\n",
    "        \n",
    "        next_state = np.array([s.observation for s in statewrappers])\n",
    "        infos = [s.env_info for s in statewrappers]\n",
    "\n",
    "        for i in range(len(envs)):\n",
    "            debug_memories[i].append((\n",
    "                state[i],\n",
    "                action[i],\n",
    "                next_state[i],\n",
    "                rewards[i],\n",
    "                terminals[i],\n",
    "                infos[i]\n",
    "            ))\n",
    "        \n",
    "        if np.any(terminals):\n",
    "            next_state[terminals] = [e.reset()[0] for e,t in zip(envs, terminals) if t]\n",
    "        \n",
    "        state = next_state\n",
    "    \n",
    "    return debug_memories, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sph3re/.anaconda3/envs/rlagent2/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "snapshotter = Snapshotter()\n",
    "tf.keras.backend.clear_session()\n",
    "with tf.compat.v1.Session():\n",
    "    data = snapshotter.load('data/local/experiment/ppo_car', itr=10)\n",
    "    policy = data['algo'].policy\n",
    "    env = data['env']\n",
    "    with Pool(4) as p:\n",
    "        path = p.map(lambda x: garage.rollout(env, policy, deterministic=True, max_episode_length=1000), range(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rGap', 'rFollow', 'rAccel', 'rJerk', 'rKrit', 'vOpt', 'bKin'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[\"env_infos\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': 13.710673332214355,\n",
       " 'speed': 7.199314117431641,\n",
       " 'accel': 1.9717025756835938,\n",
       " 'jerk': -0.02829742431640625}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.owncar.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlagent2",
   "language": "python",
   "name": "rlagent2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
